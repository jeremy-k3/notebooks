{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9JBHpMQJ--A"
      },
      "source": [
        "# üõ†Ô∏è Implementation of RAG using LlamaIndex\n",
        "\n",
        "**This notebook provides an implementation of a simple RAG system using LlamaIndex and comparing results with 2 small LLMs: TinyLlama1.1B and Zephyr-7b-gemma-v0.1<br>It also uses FAISS as a vector database and sentence-transformers as en embedding model.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViVpAMOlsAZX"
      },
      "source": [
        "## üß∞ Install required dependencies\n",
        "* LlamaIndex\n",
        "* Langchain to use a custom embedding model with LlamaIndex\n",
        "* Faiss as a vector storage\n",
        "* sentence-transformers as an embedding model\n",
        "* torch to run the LLM using a GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0U8-Z1B-Jzrh"
      },
      "outputs": [],
      "source": [
        "! pip install llama-index==0.10.18\n",
        "! pip install langchain==0.1.11\n",
        "! pip install faiss-gpu\n",
        "! pip install sentence-transformers\n",
        "! pip install torch==2.2.1\n",
        "! pip install accelerate\n",
        "! pip install pypdf\n",
        "! pip install llama-index-vector-stores-faiss\n",
        "! pip install llama-index-embeddings-langchain\n",
        "! pip install llama-index-embeddings-huggingface\n",
        "! pip install llama-index-llms-huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p5M6mU8s0QV"
      },
      "source": [
        "## üì• Import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "r8dIzhTF3Bin"
      },
      "outputs": [],
      "source": [
        "#Core LlamaIndex\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "from llama_index.core import (\n",
        "    SimpleDirectoryReader,\n",
        "    load_index_from_storage,\n",
        "    VectorStoreIndex,\n",
        "    StorageContext,\n",
        "    Settings\n",
        ")\n",
        "\n",
        "#Vector storage\n",
        "import faiss\n",
        "from llama_index.vector_stores.faiss import FaissVectorStore\n",
        "\n",
        "#Embedding model\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "#LLM\n",
        "import torch\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "\n",
        "#Other useful modules\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RftABV5JCWKs"
      },
      "source": [
        "## üîÑ Load the document\n",
        "\n",
        "\n",
        "### Document is retrieved from the Internet. Change URL if you want to use another document"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O quantum.pdf  https://www.dst.defence.gov.au/sites/default/files/events/documents/Quantum%20Computing%20Insights%20Paper.pdf"
      ],
      "metadata": {
        "id": "420VtmjDCswE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzXJO2CusnW9"
      },
      "outputs": [],
      "source": [
        "reader = SimpleDirectoryReader(\n",
        "    input_files=[\"quantum.pdf\"]\n",
        ")\n",
        "documents = reader.load_data()\n",
        "\n",
        "print('Number of pages:', len(documents))\n",
        "print(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylE2UzuotR2K"
      },
      "source": [
        "## üß© Create nodes\n",
        "\n",
        "In LlamaIndex, documents are transformed into nodes, which are smaller data units (i.e. chunks).\n",
        "We use a node parser that tries to keep the sentences and paragraphs together. The max chunk size is set to 512 tokens with an overlap of 20 tokens if the paragraphs has to be splitted.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqw_Cc2ctJys",
        "outputId": "30dd8e09-700f-4c3d-bb6a-2e93b32051ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes created: 102\n",
            "[TextNode(id_='1350f00d-c1a6-44ce-ab06-4c72e7dc5d1c', embedding=None, metadata={'page_label': '1', 'file_name': 'quantum.pdf', 'file_path': 'quantum.pdf', 'file_type': 'application/pdf', 'file_size': 1962431, 'creation_date': '2024-03-12', 'last_modified_date': '2022-07-25'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='5c69ea8f-9699-472d-83e2-4737658da046', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '1', 'file_name': 'quantum.pdf', 'file_path': 'quantum.pdf', 'file_type': 'application/pdf', 'file_size': 1962431, 'creation_date': '2024-03-12', 'last_modified_date': '2022-07-25'}, hash='d9b7731ae566d47707c6cd1f6bf9c74049f15203b9228c62ffeeac73457ab24f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='865b9fb4-94d3-4782-baca-f3cac65bf5ae', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='cda36bec94db12ead77baf2c022f956cc735ec07377f04e3edb8b7382190e0dc')}, text='QUANTUM \\nCOMPUTING\\nINSIGHTS PAPER', start_char_idx=0, end_char_idx=33, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
            " TextNode(id_='865b9fb4-94d3-4782-baca-f3cac65bf5ae', embedding=None, metadata={'page_label': '2', 'file_name': 'quantum.pdf', 'file_path': 'quantum.pdf', 'file_type': 'application/pdf', 'file_size': 1962431, 'creation_date': '2024-03-12', 'last_modified_date': '2022-07-25'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='2e361946-869d-4b8a-ad4d-807e4bb77deb', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '2', 'file_name': 'quantum.pdf', 'file_path': 'quantum.pdf', 'file_type': 'application/pdf', 'file_size': 1962431, 'creation_date': '2024-03-12', 'last_modified_date': '2022-07-25'}, hash='382bb684ebf0a48ec62171fc3c744302f9edc0645315bcd01ef9c999abfb1f23'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1350f00d-c1a6-44ce-ab06-4c72e7dc5d1c', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '1', 'file_name': 'quantum.pdf', 'file_path': 'quantum.pdf', 'file_type': 'application/pdf', 'file_size': 1962431, 'creation_date': '2024-03-12', 'last_modified_date': '2022-07-25'}, hash='d9b7731ae566d47707c6cd1f6bf9c74049f15203b9228c62ffeeac73457ab24f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9bf229d7-b851-4ac1-9a13-1280dcc2782a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c1380c8ce24e2d15474ed98ed9a6344c62694e9f9b76e326da935ebb4f1c6ac6')}, text='2\\nEMERGING DISRUPTIVE TECHNOLOGY  \\nASSESSMENT SYMPOSIUMAcknowledgements\\nThe author of this paper is Noetic under contract to the Department of Defence. Noetic would \\nlike to acknowledge the insights provided during subject matter expert interviews of a range \\nof people drawn from academia, industry, and Defence, which underpin the development \\nof this paper. This paper also leverages previous work undertaken by Noetic and Defence \\nScience and Technology Group (DSTG) for the 2021 Quantum Computing: In Focus  event. Noetic \\nalso wishes to acknowledge the review and arising comments on the draft paper provided by \\nDSTG and EDTAS Technology Opportunities Event Partners.', start_char_idx=0, end_char_idx=674, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
            " TextNode(id_='9bf229d7-b851-4ac1-9a13-1280dcc2782a', embedding=None, metadata={'page_label': '3', 'file_name': 'quantum.pdf', 'file_path': 'quantum.pdf', 'file_type': 'application/pdf', 'file_size': 1962431, 'creation_date': '2024-03-12', 'last_modified_date': '2022-07-25'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='0ff84060-1dd2-4c60-abfd-9203ac1b473c', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '3', 'file_name': 'quantum.pdf', 'file_path': 'quantum.pdf', 'file_type': 'application/pdf', 'file_size': 1962431, 'creation_date': '2024-03-12', 'last_modified_date': '2022-07-25'}, hash='914f05cb91b09855c13640663337212c79d6523940bf7d14da38abe4a9c1827a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='865b9fb4-94d3-4782-baca-f3cac65bf5ae', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '2', 'file_name': 'quantum.pdf', 'file_path': 'quantum.pdf', 'file_type': 'application/pdf', 'file_size': 1962431, 'creation_date': '2024-03-12', 'last_modified_date': '2022-07-25'}, hash='382bb684ebf0a48ec62171fc3c744302f9edc0645315bcd01ef9c999abfb1f23'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2e450848-de51-4b99-9d64-0a2b9fcd7dee', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ac3dc63e65d769fe9f7a4205ac32a74df6a13687463f815ac51a1eb71a662054')}, text='3\\nQUANTUM COMPUTING  \\nINSIGHTS PAPER\\n‚ÄúThe true test of insight is \\nwhether you can help them \\nimprove it or build something  \\nof your own‚Äù\\nAdam Grant | 3 June 2022', start_char_idx=0, end_char_idx=163, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n"
          ]
        }
      ],
      "source": [
        "# Initialize the parser\n",
        "parser = SentenceSplitter.from_defaults(chunk_size=512, chunk_overlap=20)\n",
        "\n",
        "import pprint\n",
        "# Parse documents into nodes\n",
        "nodes = parser.get_nodes_from_documents(documents)\n",
        "print(f\"Number of nodes created: {len(nodes)}\")\n",
        "pprint.pprint([nodes[i] for i in range(3)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en8tHk-WtsXx"
      },
      "source": [
        "## üõ¢ Store the embeddings of the nodes into a vector store (Faiss)\n",
        "\n",
        "In order to query the nodes, we extract their embeddings and store them in a vector store. We will use Faiss here but many other options are available.\n",
        "\n",
        "Regarding the embedding model, we will use sentence-transformers as it is a performant open-source model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95pNdM4kuF0u"
      },
      "outputs": [],
      "source": [
        "#Create a Faiss index. 768 is the dimensionality of the embeddings generated by sentence-transformers\n",
        "faiss_index = faiss.IndexFlatL2(768)\n",
        "\n",
        "#Load the embedding model\n",
        "Settings.embed_model = LangchainEmbedding(\n",
        "  HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        ")\n",
        "\n",
        "#Define ServiceContext which is needed to create the index. As we have not instantiated the LLM so far, we set it as None\n",
        "#service_context = ServiceContext.from_defaults(llm=None, embed_model=embed_model)\n",
        "\n",
        "#Create a vector storage and its context\n",
        "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "#Add the embeddings to the index\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, storage_context=storage_context#, service_context=service_context\n",
        ")\n",
        "\n",
        "# save index to disk. Will be stored in ./storage by default\n",
        "index.storage_context.persist()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOt0rNUpzKft"
      },
      "source": [
        "## üß† Instantiate the LLM\n",
        "\n",
        "Choose one of these two."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  If you want to test TinyLlama1.1B"
      ],
      "metadata": {
        "id": "rbejDhwSut0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Settings.llm = HuggingFaceLLM(\n",
        "    context_window=2048,\n",
        "    max_new_tokens=512,\n",
        "    generate_kwargs={\"temperature\": 0.1, \"do_sample\": False},\n",
        "    tokenizer_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "    model_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "    tokenizer_kwargs={\"max_length\": 2048},\n",
        "    model_kwargs={\"torch_dtype\": torch.float16}\n",
        ")"
      ],
      "metadata": {
        "id": "wl4sQ4ybvMw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To use Zephyr-7b-gemma-v0,1"
      ],
      "metadata": {
        "id": "vMACZZ6WzpM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Settings.llm = HuggingFaceLLM(\n",
        "    context_window=2048,\n",
        "    max_new_tokens=512,\n",
        "    generate_kwargs={\"temperature\": 0.1, \"do_sample\": False},\n",
        "    tokenizer_name=\"HuggingFaceH4/zephyr-7b-beta\",\n",
        "    model_name=\"HuggingFaceH4/zephyr-7b-beta\",\n",
        "    tokenizer_kwargs={\"max_length\": 2048},\n",
        "    model_kwargs={\"torch_dtype\": torch.float16}\n",
        ")"
      ],
      "metadata": {
        "id": "PsN0uwibzrME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ssb_tUCIAPd"
      },
      "source": [
        "## ü§î Query the document\n",
        "\n",
        "We retrieve the index (not really needed here but could be useful if querying is done later than creating the index).\n",
        "\n",
        "Then, we define a query engine with this index and ask our question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pt-9bvMU0rR1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5b2fa1c-7e2f-4bdd-dcf6-b8c4a89622b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 1.3071348667144775\n"
          ]
        }
      ],
      "source": [
        "stored_index = load_index_from_storage(storage_context)\n",
        "\n",
        "query_engine = stored_index.as_query_engine()\n",
        "prompt=\"What is quantum computing?\"\n",
        "#prompt=\"What will quantum computing be capable of in 2040?\"\n",
        "#prompt=\"What are the ethical challenges related to quantum computing?\"\n",
        "import time\n",
        "t0=time.time()\n",
        "response = query_engine.query(prompt)\n",
        "print(f\"Time: {time.time()-t0}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHUA-8nnIYnf"
      },
      "source": [
        "## üîé Display response and sources in a table"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", -1)\n",
        "\n",
        "\n",
        "def pretty_print(df):\n",
        "    return display(HTML(df.to_html().replace(\"\\\\n\", \"<br>\")))\n",
        "\n",
        "\n",
        "def visualize_retrieved_nodes(nodes) -> None:\n",
        "    result_dicts = []\n",
        "    for node in nodes:\n",
        "        result_dict = {\"Score\": node.score, \"Text\": node.node.get_text()}\n",
        "        result_dicts.append(result_dict)\n",
        "\n",
        "    pretty_print(pd.DataFrame(result_dicts))\n",
        "\n",
        "\n",
        "print(response.response)\n",
        "\n",
        "nodes= response.source_nodes\n",
        "visualize_retrieved_nodes(nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wVIsIAWGNtOG",
        "outputId": "59ea0683-e7c7-45a9-e40d-8efcaa9b71bf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantum computing is a general model for modelling information and how information sciences work. It is considered more accurate and more tied to the physical world than what has been used before.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-3ac505d74576>:5: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  pd.set_option(\"display.max_colwidth\", -1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.612567</td>\n",
              "      <td>16<br>EMERGING DISRUPTIVE TECHNOLOGY  <br>ASSESSMENT SYMPOSIUMIn broad terms the layers indicated in Figure 1 are:<br>Algorithms and Applications.  In this layer, applications are mapped into <br>a set of quantum computer algorithms which together solve a specified <br>problem. However, it needs to be acknowledged that quantum computers <br>are co-processors, and that the vast majority of applications will require <br>orchestration of quantum and classical computers working together.<br>Software, Compilation, and Control.  This layer includes a quantum <br>programming language, which the algorithms required are translated <br>into:<br> +A compiler that maps these programs to logical qubit operations<br> +A scheduler and optimiser for the logical qubit operations <br> +Error correction firmware within which logical qubits are mapped <br>to underlying physical qubits.<br>Hardware.  This layer includes physical level schedulers, optimisers, <br>and device control firmware.<br>Qubits.  In this layer specific pulses are produced which control <br>each qubit. In addition this layer includes readout of qubit values. <br>These values are fed back up to higher layers to implement fault <br>tolerant error correction and calculation output.<br>Networking and Integration.  Communication and quantum state <br>transfer between quantum computers for distributed computation and <br>communication, including integration with hybrid systems and networks.<br>Further explanatory information regarding quantum computing and ‚Äòthe <br>stack‚Äô is contained in Annex B.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.679680</td>\n",
              "      <td>22<br>EMERGING DISRUPTIVE TECHNOLOGY  <br>ASSESSMENT SYMPOSIUMDespite being at a relatively early stage of development, some argue <br>that quantum computing has already changed computer science. For <br>example, quantum computing has stimulated debates in computing and <br>information sciences as to whether Alan Turing‚Äôs (computational) model <br>of what a computer is ‚Äì which is what we have in the form of classical <br>computers ‚Äì is the most complete model of what computing could be or <br>should be. With the advent of the quantum computing model it is now <br>apparent that this is not the case, especially if you take efficiencies into <br>account. Quantum computing is a more general model for modelling <br>information and how information sciences work. It is considered more <br>accurate and more tied to the physical world than what has been used <br>before. As such, quantum computing has contested previous thinking <br>regarding information and computing theory.<br>Many envisage quantum computing as a means to augment classical <br>computers, not to replace them. Indeed, there will be a symbiosis. <br>Development in quantum computing will improve classical computers <br>e.g. classical computer programmers have derived better algorithms <br>for classical computers from quantum algorithms. As such, classical <br>computers will become more powerful alongside quantum computers. <br>In some ways quantum computers are analogous to the turbo in a motor <br>car, where it isn‚Äôt needed all the time, but operates when it is required to <br>enhance performance. Stand-alone quantum computers will also require <br>classical computers to operate them.<br>In the coming years impacts from quantum computing may be seen in <br>investment portfolio optimisation from financial institutions and other <br>entities seeking high risk, but high pay off ventures. Similarly, impacts <br>may be seen in encryption for secure transactions, which can potentially <br>be offset by the upgrading to post quantum cryptography, but as quantum <br>computing hardware emerges this will need to be continually monitored. <br>Changes could be seen in the landscape of industry, from advanced <br>manufacturing through to increased simulation capability, the study of <br>new molecules within health sciences, improvements in robotics and <br>autonomous systems, or new, currently unknown industries could emerge.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
